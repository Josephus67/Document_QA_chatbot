{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "326ff4b0-aa7a-4a49-b92b-4d434db1d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8a27c56-42a1-4feb-9a1f-85dcd77d23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "#df = pd.read_csv('./npr.csv')  # Ensure npr.csv is in the correct path\n",
    "#sample_document = df['Article'].iloc[1]\n",
    "\n",
    "with open('./machine_learning_nlp.txt') as f:\n",
    "    sample_document = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86085421-e156-4a5c-a8c5-a9b36faa9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text (lemmatization, keep for consistency)\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return doc  # Return spaCy Doc for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2db4996-1248-4994-bddd-fdb25c4a1a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentence embedding by averaging token vectors\n",
    "def get_embedding(doc):\n",
    "    # Average non-stop, non-punctuation token vectors\n",
    "    vectors = [token.vector for token in doc if not token.is_stop and not token.is_punct]\n",
    "    if not vectors:  # Handle empty vectors\n",
    "        return np.zeros(nlp.vocab.vectors.shape[1])\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f57bfdb0-0a31-42bd-b4da-7aa9c8fce819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process document into sentences\n",
    "def process_document(document):\n",
    "    doc = nlp(document)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "    sentence_docs = [preprocess_text(sent) for sent in sentences]\n",
    "    sentence_embeddings = [get_embedding(doc) for doc in sentence_docs]\n",
    "    return sentences, sentence_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccee44-d260-43a4-a849-ad13411c64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find best matching sentences\n",
    "def get_best_response(user_input, sentence_embeddings, sentences):\n",
    "    # Preprocess and embed user input\n",
    "    input_doc = preprocess_text(user_input)\n",
    "    input_embedding = get_embedding(input_doc)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity([input_embedding], sentence_embeddings)[0]\n",
    "    \n",
    "    # Get top 2 sentences above threshold\n",
    "    threshold = 0.4 \n",
    "    top_indices = np.argsort(similarities)[::-1][:2]  # Top 2\n",
    "    responses = []\n",
    "    for idx in top_indices:\n",
    "        if similarities[idx] > threshold:\n",
    "            responses.append((sentences[idx], similarities[idx]))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if not responses:\n",
    "        return \"Sorry, I donâ€™t have relevant information about that in the document.\", 0.0\n",
    "    return responses, max(similarities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "738ef464-f0d0-47d0-92f7-1ed268203c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! Ask me about the document (type 'exit'or 'quit' to quit).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  what is machine learning?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Categories of Machine Learning\n",
      "Machine Learning encompasses several approaches, each suited to different types of problems:\n",
      "\n",
      "Supervised Learning: (Similarity: 0.87)\n",
      "Chatbot: What is Machine Learning?\n",
      "Machine Learning is a subfield of AI that empowers computers to learn from data and improve over time without being explicitly programmed. (Similarity: 0.87)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  decision trees\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Both fields require significant computational resources, raising concerns about energy consumption and accessibility. (Similarity: 0.61)\n",
      "Chatbot: As researchers and engineers push the boundaries of these fields, ML and NLP will continue to drive innovation, making technology more intelligent, accessible, and human-centric. (Similarity: 0.60)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Chatbot function\n",
    "def chatbot(document):\n",
    "    sentences, sentence_embeddings = process_document(document)\n",
    "    if not sentences:\n",
    "        print(\"Error: No valid sentences found in the document.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Chatbot: Hello! Ask me about the document (type 'exit'or 'quit' to quit).\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\"or user_input.lower() == \"quit\":\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        response, max_similarity = get_best_response(user_input, sentence_embeddings, sentences)\n",
    "        if isinstance(response, str):\n",
    "            print(f\"Chatbot: {response} (Similarity: {max_similarity:.2f})\")\n",
    "        else:\n",
    "            for sent, sim in response:\n",
    "                print(f\"Chatbot: {sent} (Similarity: {sim:.2f})\")\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot(sample_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7c707-5ac7-4ed0-945d-1debc4c368df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
